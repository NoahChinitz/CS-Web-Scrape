{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from bs4 import BeautifulSoup\n","import requests\n","import re\n","import csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Requests initial HTML page\n","URL = 'https://eecs.berkeley.edu/about/special-events/rising-stars/participants?_ga=2.234656926.1816269636.1634504085-1140340477.1634504085'\n","page = requests.get(URL)\n","soup = BeautifulSoup(page.content, 'html.parser')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Gets list of all \"Group Pages\"\n","href_list = []\n","href_list = soup.find_all('a', href=True)\n","group_list = []\n","\n","for item in href_list:\n","    if item.has_attr('href'):\n","        href = item['href'].find('https://www2.eecs.berkeley.edu/risingstars/2020/participants/')\n","        if href != -1:\n","            group_list.append(item['href'])\n","            group_list = list(set(group_list))\n","\n","# Gets each participants Berkeley page \n","participants_list = []\n","participants_url_list = []\n","\n","# Shaves the entries down to just html page \n","for url in group_list:\n","    page = requests.get(url)\n","    soup = BeautifulSoup(page.content, 'html.parser')\n","    participants_list = soup.find_all('div', class_='col-md-3 col-sm-6 col-xs-12')\n","    for item in participants_list:\n","        regex = \"\\\".*shtml\\\"\"\n","        participants_url_list.append(re.findall(regex, str(item.find('a'))))\n","\n","# Reformats URL list\n","real_url_list = []\n","for url in participants_url_list:\n","    regex = \"[^\\[\\'\\\"].*shtml\"\n","    real_url_list.append(re.findall(regex, str(url)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Sets up CSV\n","field_names= ['name', 'position', 'institution', 'institution2', 'interest_areas', 'poster', 'abstract', 'bio', 'website']\n","csv_file = open('rising_stars_2020.csv', 'w+')\n","writer = csv.writer(csv_file)\n","\n","# Collects all the data\n","base_string = 'https://www2.eecs.berkeley.edu/risingstars/2020/participants/'\n","people_list = []\n","for url in real_url_list:\n","    if len(url) > 0:\n","        page = requests.get(base_string + url[0])\n","        soup = BeautifulSoup(page.content, 'html.parser')\n","        person = {}\n","        try:\n","            print('NAME: ' + soup.find_all('h1')[1].contents[5].replace('\\n', '').strip())\n","            person[\"name\"] = soup.find_all('h1')[1].contents[5].replace('\\n', '').strip()\n","        except:\n","            person['name'] = ''\n","\n","        try:\n","            print('POSITION: ' + soup.find_all('h2', class_=False)[0].contents[2].replace('\\n', ''))\n","            person[\"position\"] = soup.find_all('h2', class_=False)[0].contents[2].replace('\\n', '')\n","        except:\n","            person['position'] = ''\n","\n","        try:\n","            print('INSTITUTION: ' + soup.find_all('h3', class_=False)[0].contents[2].replace('\\n', ''))\n","            person[\"institution\"] = soup.find_all('h3', class_=False)[0].contents[2].replace('\\n', '')\n","        except:\n","            person['institution'] = ''\n","\n","        try:\n","            print('INSTITUTION2: ' + soup.find_all('h4', class_=False)[0].contents[4].replace('\\n', ''))\n","            person[\"institution2\"] = soup.find_all('h4', class_=False)[0].contents[4].replace('\\n', '')\n","        except:\n","            person['institution2'] = ''\n","\n","        try:\n","            print('INTERESTS: ' + soup.find_all('ul', class_=False)[0].prettify().replace('<ul>', '').replace('</ul>', '').replace('<li>', '').replace('</li>', '').replace('\\n', '').replace('<!-- research areas here separated by LI tags -->', '').replace('<!-- end areas -->', ''))\n","            person[\"interest_areas\"] = soup.find_all('ul', class_=False)[0].prettify().replace('<ul>', '').replace('</ul>', '').replace('<li>', '').replace('</li>', '').replace('\\n', '').replace('<!-- research areas here separated by LI tags -->', '').replace('<!-- end areas -->', '')\n","        except:\n","            person['interest_areas'] = ''\n","\n","        try:\n","            print('POSTER: ' + soup.find_all('p', class_=False)[0].contents[1].prettify().replace('<em>', '').replace('</em>', '').replace('<!-- poster title here -->', '').replace('<!-- end poster title -->', '').replace('\\n', ''))\n","            person[\"poster\"] = soup.find_all('p', class_=False)[0].contents[1].prettify().replace('<em>', '').replace('</em>', '').replace('<!-- poster title here -->', '').replace('<!-- end poster title -->', '').replace('\\n', '')\n","        except:\n","            person['poster'] = ''\n","\n","        try:\n","            print('ABSTRACT: ' + soup.find_all('p', class_=False)[1].contents[2].replace('\\n', ''))\n","            person['abstract'] = soup.find_all('p', class_=False)[1].contents[2].replace('\\n', '')\n","        except:\n","            person['abstract'] = ''\n","\n","        try:\n","            print('BIO: ' + soup.find_all('p', class_=False)[2].contents[2].replace('\\n', ''))\n","            person['bio'] = soup.find_all('p', class_=False)[2].contents[2].replace('\\n', '')\n","        except:\n","            person['bio'] = ''\n","\n","        try:\n","            print('WEBSITE: ' + soup.find_all('p', class_=False)[3].contents[3].prettify().replace('\\n', '').replace('<a href=\"', '').replace('\"> Personal home page</a>', ''))\n","            person['website'] = soup.find_all('p', class_=False)[3].contents[3].prettify().replace('\\n', '').replace('<a href=\"', '').replace('\"> Personal home page</a>', '')\n","        except:\n","            person['website'] = ''    \n","\n","        print('\\n')\n","        people_list.append(person)\n","\n","        for key, value in person.items():\n","            writer.writerow([key,value])\n","        writer.writerow(['',''])\n","\n","# Closes CSV\n","csv_file.close()"]}],"metadata":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"},"kernelspec":{"display_name":"Python 3.8.10 64-bit","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
